{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "#               Read the Input Training and Test File           \n",
    "#===============================================================================\n",
    "import pandas as pd\n",
    "train = pd.read_csv('tweets_file_dmy.txt', skiprows = 1, names= [\"ItemID\", \"Sentiment\", \"SentimentSource\", \"SentimentText\"])\n",
    "test = pd.read_csv('tweets_file_test.txt', skiprows = 1, names= [\"ItemID\", \"Sentiment\", \"SentimentSource\", \"SentimentText\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vipul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#===============================================================================\n",
    "#                         Data Cleaning                                   \n",
    "#===============================================================================\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt\n",
    "\n",
    "#Data Clean and tokenize function\n",
    "def clean_data(text):\n",
    "    text['clean_tweet'] = np.vectorize(remove_pattern)(text['SentimentText'], \"@[\\w]*\")\n",
    "    text['clean_tweet'] = text['clean_tweet'].apply(lambda x: x.lower())\n",
    "    text['clean_tweet'] = text['clean_tweet'].str.replace(\"[^a-z0-9#]\", \" \")\n",
    "    text['tokenized_tweet'] = text['clean_tweet'].apply(lambda x: x.split())\n",
    "    text['tokenized_tweet'] = text['tokenized_tweet'].apply(lambda x: [i for i in x if i not in stop])\n",
    "    text['tokenized_tweet'] = text['tokenized_tweet'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "    text['tokenized_tweet'] = text['tokenized_tweet'].apply(lambda x: ' '.join([w for w in x]))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the train and test data\n",
    "cleaned_train = clean_data(train)\n",
    "cleaned_test = clean_data(test)\n",
    "test_target = cleaned_data_test['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           sad apl friend\n",
      "1                                    miss new moon trailer\n",
      "2                                         omg alreadi 7 30\n",
      "3        omgaga im sooo im gunna cri dentist sinc 11 su...\n",
      "4                                        think mi bf cheat\n",
      "                               ...                        \n",
      "89984    gnome hat problem finish size pointi top mama ...\n",
      "89985    saw linn bakeri thought veggi friendli worri f...\n",
      "89986                                           would love\n",
      "89987                                                 evid\n",
      "89988    spine thing sound good back exercis fun best l...\n",
      "Name: tokenized_tweet, Length: 89989, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_train['tokenized_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=10, stop_words='english')\n",
    "\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(cleaned_train['tokenized_tweet']).toarray()\n",
    "tfidf_test = tfidf_vectorizer.transform(cleaned_test['tokenized_tweet']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>sad apl friend</td>\n",
       "      <td>is so sad for my apl frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>miss new moon trailer</td>\n",
       "      <td>i missed the new moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg alreadi 7 30</td>\n",
       "      <td>omg its already 7 30  o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga im sooo im gunna cri dentist sinc 11 su...</td>\n",
       "      <td>omgaga  im sooo  im gunna cry  i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>think mi bf cheat</td>\n",
       "      <td>i think mi bf is cheating on me      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89984</td>\n",
       "      <td>89996</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@clevercatsknit Re: gnome hat. Was the problem...</td>\n",
       "      <td>gnome hat problem finish size pointi top mama ...</td>\n",
       "      <td>re  gnome hat  was the problem the finished s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89985</td>\n",
       "      <td>89997</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@clevercatsknit Saw Linnes Bakery but thought ...</td>\n",
       "      <td>saw linn bakeri thought veggi friendli worri f...</td>\n",
       "      <td>saw linnes bakery but thought it not too vegg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89986</td>\n",
       "      <td>89998</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@cleverdaisies I would LOVE to!!!</td>\n",
       "      <td>would love</td>\n",
       "      <td>i would love to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89987</td>\n",
       "      <td>89999</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@cleverick evidently not</td>\n",
       "      <td>evid</td>\n",
       "      <td>evidently not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89988</td>\n",
       "      <td>90000</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@cleverindie This spine thing sounds no good  ...</td>\n",
       "      <td>spine thing sound good back exercis fun best l...</td>\n",
       "      <td>this spine thing sounds no good  back exercis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89989 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment SentimentSource  \\\n",
       "0           1          0    Sentiment140   \n",
       "1           2          0    Sentiment140   \n",
       "2           3          1    Sentiment140   \n",
       "3           4          0    Sentiment140   \n",
       "4           5          0    Sentiment140   \n",
       "...       ...        ...             ...   \n",
       "89984   89996          1    Sentiment140   \n",
       "89985   89997          1    Sentiment140   \n",
       "89986   89998          1    Sentiment140   \n",
       "89987   89999          0    Sentiment140   \n",
       "89988   90000          0    Sentiment140   \n",
       "\n",
       "                                           SentimentText  \\\n",
       "0                           is so sad for my APL frie...   \n",
       "1                         I missed the New Moon trail...   \n",
       "2                                omg its already 7:30 :O   \n",
       "3                .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4               i think mi bf is cheating on me!!!   ...   \n",
       "...                                                  ...   \n",
       "89984  @clevercatsknit Re: gnome hat. Was the problem...   \n",
       "89985  @clevercatsknit Saw Linnes Bakery but thought ...   \n",
       "89986                 @cleverdaisies I would LOVE to!!!    \n",
       "89987                          @cleverick evidently not    \n",
       "89988  @cleverindie This spine thing sounds no good  ...   \n",
       "\n",
       "                                         tokenized_tweet  \\\n",
       "0                                         sad apl friend   \n",
       "1                                  miss new moon trailer   \n",
       "2                                       omg alreadi 7 30   \n",
       "3      omgaga im sooo im gunna cri dentist sinc 11 su...   \n",
       "4                                      think mi bf cheat   \n",
       "...                                                  ...   \n",
       "89984  gnome hat problem finish size pointi top mama ...   \n",
       "89985  saw linn bakeri thought veggi friendli worri f...   \n",
       "89986                                         would love   \n",
       "89987                                               evid   \n",
       "89988  spine thing sound good back exercis fun best l...   \n",
       "\n",
       "                                             clean_tweet  \n",
       "0                           is so sad for my apl frie...  \n",
       "1                         i missed the new moon trail...  \n",
       "2                                omg its already 7 30  o  \n",
       "3                   omgaga  im sooo  im gunna cry  i ...  \n",
       "4               i think mi bf is cheating on me      ...  \n",
       "...                                                  ...  \n",
       "89984   re  gnome hat  was the problem the finished s...  \n",
       "89985   saw linnes bakery but thought it not too vegg...  \n",
       "89986                                i would love to      \n",
       "89987                                     evidently not   \n",
       "89988   this spine thing sounds no good  back exercis...  \n",
       "\n",
       "[89989 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf\n",
    "train_target = cleaned_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for sigmoid, gradient descent, weight update and accuracy calculation\n",
    "def sigmoid(X, weight):\n",
    "    z = np.dot(X, weight)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def gradient_descent(X, h, y):\n",
    "    return np.dot(X.T, (h - y)) / y.shape[0]\n",
    "\n",
    "def update_weight_loss(weight, learning_rate, gradient):\n",
    "    return weight - learning_rate * gradient\n",
    "\n",
    "def predict_t(x, theta):\n",
    "    theta_new = theta[:, np.newaxis]\n",
    "    return sigmoid(x,theta_new)\n",
    "\n",
    "def acc_calc(actual, pred):\n",
    "    predicted_class = ((pred >= 0.5) .astype(int))\n",
    "    predicted_class = predicted_class.flatten()\n",
    "    acc = np.mean(predicted_class == actual)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for running gradient descent\n",
    "def run_grad(X, y):\n",
    "    num_iter = 100\n",
    "   \n",
    "    theta = np.zeros(X.shape[1])\n",
    " \n",
    "    for i in range(num_iter):\n",
    "        h = sigmoid(X, theta)\n",
    "        gradient = gradient_descent(X, h, y)\n",
    "        theta = update_weight_loss(theta, 0.1, gradient)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# K-fold Cross Validation\n",
    "kfoldcv = KFold(10, True, 1)\n",
    "bestacc = 0\n",
    "theta_final = np.zeros(X.shape[1])\n",
    "\n",
    "# Enumerate splits\n",
    "for train, test in kfoldcv.split(X):\n",
    "    X_train = X[train]\n",
    "    X_validate = X[test]\n",
    "    \n",
    "    Y_train = train_target[train]\n",
    "    Y_validate = train_target[test]\n",
    "    \n",
    "    theta_out = run_grad(X_train, Y_train)\n",
    "    \n",
    "    pred = predict_t(X_validate, theta_out)\n",
    "    \n",
    "    acc = acc_calc(Y_validate, pred)\n",
    "    \n",
    "    if(acc > bestaccuracy):\n",
    "        theta_final = theta_out\n",
    "        bestacc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.17983528e-04 3.96188669e-04 9.77293871e-05 ... 7.12300904e-05\n",
      " 5.67245301e-05 4.92836337e-04]\n",
      "0.7033003667074119\n"
     ]
    }
   ],
   "source": [
    "print(theta_final)\n",
    "print(bestacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = predict_t(tfidf_test, theta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = acc_calc(test_target, test_out)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.81\n",
      "Precision score: 0.70\n",
      "Recall score: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, test_out)\n",
    "test_final_out = ((test_out >= 0.5) .astype(int))\n",
    "\n",
    "#Precision Score\n",
    "prec = precision_score(test_target, test_final_out)\n",
    "#Recall Score\n",
    "recall = recall_score(test_target, test_final_out)\n",
    "conf = confusion_matrix(test_target, test_final_out)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "print('Precision score: {0:0.2f}'.format(prec))\n",
    "\n",
    "print('Recall score: {0:0.2f}'.format(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
